# TIPE : Optimisation de Lenia par d√©tection de structures r√©currentes

## Objectif

L‚Äôobjectif est d‚Äôutiliser la d√©tection de cycles pour optimiser Lenia.

En ex√©cutant le Jeu de la Vie √† la main, on remarque qu‚Äôil est souvent possible de r√©duire les calculs en identifiant des structures stables, comme les oscillateurs. Il est donc raisonnable de se demander si une optimisation similaire peut √™tre appliqu√©e √† Lenia.

## Plan

1. Impl√©mentation du Jeu de la Vie  
    - Version na√Øve  
    - Version avec d√©tection de cycle  
2. Optimisation de Lenia  
    - Version na√Øve  
    - Version avec FFT  
    - Version parall√©lis√©e sur GPU  
    - Version avec d√©tection de cycle  
3. Compl√©tude de Lenia (bonus)  
    - √âcrire un algorithme g√©n√©tique pour trouver un glider gun  
    - Trouver un glider gun  

## D√©finition

On appelle simulation ce qui est d√©fini par :

- Un champ scalaire, $A : L \mapsto [0, 1]$, o√π $L$ est un espace euclidien muni de la distance $d$ (cette impl√©mentation utilise un espace euclidien en deux dimensions, mais Lenia peut √™tre impl√©ment√©e dans n‚Äôimporte quelle dimension)
- Une fonction de croissance, $G : [0, 1] \mapsto [-1, 1]$
- Un noyau de convolution, $K : \mathbb{R} \mapsto [0, 1]$, tel que  
$$
\int_{0}^{2\pi}\int_{0}^{+\infty} K(r) \,dr \, d\theta = 1
$$

o√π $K$ associe √† une distance $r$ un poids de voisinage ‚Äî plus $r$ est petit, plus le n≈ìud consid√©r√© est un voisin.

- Un pas de temps $\Delta t$

La formule pour calculer l‚Äô√©tat de $A(\vec{x})$ est :
$$
A^{t+\Delta t}(\vec{x}) = \text{clip}(A^t(\vec{x}) + \Delta t \cdot G^t(\vec{x}), 0, 1)
$$

o√π $G^t$ est le r√©sultat de l‚Äôapplication de la fonction de croissance $G$ √† la convolution de $K$ et $A^t$.

---

## Jeu de la Vie

Dans le cas du Jeu de la Vie de Conway :

- $
K(r) =
\begin{cases} 
\frac{1}{9}, & \text{si } r = 1 \text{ ou } \sqrt{2} \\ 
0, & \text{sinon}
\end{cases}
$

- $
G(s) =
\begin{cases} 
1, & \text{si } s = 2 \\ 
0, & \text{si } s = 3 \\ 
-1, & \text{sinon}
\end{cases}
$

- $\Delta t = 1$

- On prendra un champ scalaire $A^0$ initialement al√©atoire.

### Version na√Øve

On atteint difficilement les 30 g√©n√©rations par seconde.

### Version avec d√©tection de cycle

Apr√®s recherche, il appara√Æt que parmi toutes les structures oscillantes qui √©mergent naturellement avec une probabilit√© sup√©rieure √† une sur un milliard, la majorit√© oscille en seulement deux g√©n√©rations.

On choisit alors de les d√©tecter pour ne pas les recalculer.

Cette optimisation permet un gain significatif en termes de performances, augmentant la vitesse de g√©n√©ration de 30 √† 300 g√©n√©rations par seconde.

---

## Lenia

Lenia est une version continue du Jeu de la Vie.

Pour passer √† un mod√®le continu, on utilise des fonctions gaussiennes :

- $
\text{bell}(x) = \exp\left(-\frac{(x - m)^2}{2s^2}\right)
$

- $
G(v) = 2 \cdot \text{bell}(v, 0.15, 0.015) - 1
$

- $
K_R(r) = \text{bell}\left(\frac{r}{R}, 0.5, 0.15\right) \cdot \frac{1}{S_R}
$

avec
$
S_R = \int_0^{2\pi} \int_0^{+\infty} \text{bell}\left(\frac{r}{R}, 0.5, 0.15\right) \, dr \, d\theta
$

- $\Delta t \rightarrow 0$

### Version na√Øve

Absurdemment lente, m√™me pour des simulations tr√®s petites.

### Version avec FFT

Le gain est consid√©rable : on peut alors augmenter la r√©solution de la simulation par un facteur 16 tout en conservant la m√™me fr√©quence de rafra√Æchissement.


#### Algorithme de Cooley‚ÄìTukey (FFT)

la **Transform√©e de Fourier Discr√®te (DFT)** peut √™tre vue comme une simple √©valuation de polyn√¥mes.  

Si l‚Äôon consid√®re les donn√©es d‚Äôentr√©e comme les coefficients d‚Äôun polyn√¥me :

$$
P(X) = \sum_{k=0}^{n-1} a_k X^k ,
$$

alors calculer la DFT revient √† √©valuer ce polyn√¥me en $n$ points particuliers :  
les **racines $n$-i√®mes de l‚Äôunit√©**

$$
\omega_n^j = e^{-\tfrac{2 \pi i}{n} j}, \quad j = 0,1,\dots,n-1.
$$

Pour un calcul efficace on utilise la m√©thode **diviser pour r√©gner**.  

En effet, on s‚Äôaper√ßoit que pour obtenir les valeurs en $n$ points d‚Äôun polyn√¥me, il suffit de s√©parer en **parties paire et impaire** :

$$
P(X) = \sum_{k=0}^{n-1} a_k X^k 
= P_\text{pair}(X^2) + X \cdot P_\text{impair}(X^2),
$$

o√π :  
- $P_\text{pair}(X) = a_0 + a_2 X + a_4 X^2 + \cdots$  
- $P_\text{impair}(X) = a_1 + a_3 X + a_5 X^2 + \cdots$

Ainsi, au lieu d‚Äô√©valuer $P(X)$ en $n$ points, il suffit d‚Äô√©valuer $P_\text{pair}$ et $P_\text{impair}$ en $n/2$ points chacun.  
Ces points sont reli√©s par des sym√©tries : les racines de l‚Äôunit√© viennent par **paires conjugu√©es** ($\omega_n^j$ et $-\omega_n^j$).  

On obtient donc une r√©currence :

$$
T(n) = 2\,T\!\left(\tfrac{n}{2}\right) + c n, \qquad T(1) = d.
$$

√âcrivons la r√©currence sur plusieurs niveaux :

$$
\begin{aligned}
T(n) &= 2\! \left( 2\,T\!\left(\tfrac{n}{2^2}\right)+c\tfrac{n}{2} \right) + c n
     = 2^2 T\!\left(\tfrac{n}{2^2}\right) + c n\left(1+\tfrac{1}{2}\right),\\
T(n) &= 2^2\! \left( 2\,T\!\left(\tfrac{n}{2^3}\right)+c\tfrac{n}{2^2} \right) + c n\left(1+\tfrac{1}{2}\right)
     = 2^3 T\!\left(\tfrac{n}{2^3}\right) + c n\left(1+\tfrac{1}{2}+\tfrac{1}{2^2}\right).
\end{aligned}
$$

Apr√®s $k$ niveaux on obtient :

$$
T(n) = 2^k T\!\left(\tfrac{n}{2^k}\right) + c n\sum_{i=0}^{k-1} \tfrac{1}{2^i}.
$$

Choisissons $k$ tel que $\tfrac{n}{2^k}=1$, donc $k=\log_2 n$.  
Alors $2^k = n$ et $T\!\left(\tfrac{n}{2^k}\right)=T(1)=d$. D'o√π :

$$
T(n) = n\cdot d + c n\sum_{i=0}^{\log_2 n -1} \tfrac{1}{2^i}.
$$

La somme g√©om√©trique vaut :

$$
\sum_{i=0}^{\log_2 n -1} \tfrac{1}{2^i} = \frac{1 - \tfrac{1}{2^{\log_2 n}}}{1-\tfrac{1}{2}}
= 2\left(1-\tfrac{1}{n}\right).
$$

Donc :

$$
T(n) = n d + c n \cdot 2\left(1-\tfrac{1}{n}\right)
     = n d + 2c n - 2c.
$$

Pour les grandes valeurs de $n$ (termes dominants) :

$$
T(n) = \Theta(n \log n).
$$

Ainsi la solution de :

$$
T(n)=2T(n/2)+\Theta(n)
$$

est bien :

$$
T(n)=\Theta(n\log n). \quad üöÄ
$$

On obtient ainsi une complexit√© optimale en $O(n \log n)$ pour passer des coefficients aux valeurs et inversement.

---

#### Convolution

Pour effectuer les convolutions, on utilise l'**algorithme FFT 2D** qui est d√©finie comme une FFT selon un axe puis une FFT selon l'autre axe, d‚Äôo√π une complexit√© en $O(n^2 \log n)$. 

En effet, soit $A$ et $B$ deux polyn√¥mes, et soit $C = A \times B$ leur produit. On remarque que les coefficients de $C$ v√©rifient :

$$
c_k = \sum_{i+j=k} a_i \cdot b_j
$$

On voit donc qu'il s'agit exactement de la **convolution** des coefficients $a_i$ et $b_j$.

Or, par les polyn√¥mes d'interpolation de Lagrange, on sait qu'un polyn√¥me de degr√© $n$ peut √™tre repr√©sent√© par ses **valeurs en $n$ points distincts**.  

Ainsi, pour multiplier $A$ et $B$ :  
1. On √©value $A$ en $n$ points $(x_0, x_1, \dots, x_{n-1})$ ‚Üí valeurs $A(x_i)$  
2. On √©value $B$ aux m√™mes points ‚Üí valeurs $B(x_i)$  
3. On multiplie **point par point** :  
   $$
   C(x_i) = A(x_i) \cdot B(x_i)
   $$  
4. On retrouve ensuite les coefficients de $C$ via l'interpolation de Lagrange.

üí° L'id√©e cl√© : la FFT permet de transformer la **convolution des coefficients** en une **multiplication point par point** tr√®s rapide.

---

Si l'on r√©sout directement le syst√®me d'interpolation, la complexit√© est trop √©lev√©e ($O(n^2)$ par √©tape).  

Pour y rem√©dier, on **choisit astucieusement les points** d'√©valuation : les **racines de l'unit√©**, ce qui permet d'utiliser la **FFT**.

En effet la FFT n‚Äôest rien d‚Äôautre qu‚Äôune m√©thode efficace pour obtenir les $n$ valeurs  

$$
P(\omega_n^j), \quad j = 0,1,\dots,n-1,
$$

c‚Äôest-√†-dire l‚Äô√©valuation simultan√©e du polyn√¥me $P$ en $n$ points bien choisis.

Pour faire une convolution, on a deux FFT 2D √† effectuer et une multiplication point par point en $O(n^2)$.  
On obtient donc la convolution en $O(n^2 \log n)$ √©galement.  

üëâ Contre $O(n^4)$ pour la version na√Øve.

### Version parall√©lis√©e sur GPU

#### Probl√®me des calculs inutiles

Pour qu‚Äôune cellule passe √† un √©tat non nul (vivant), elle doit avoir au moins une voisine active dans son voisinage. Or, en pratique, de nombreuses cellules sont recalcul√©es inutilement.

Une solution possible consiste √† ne calculer que les cellules susceptibles d‚Äô√™tre modifi√©es √† l‚Äô√©tat suivant.

#### Utilisation de CUDA pour parall√©liser

On atteint ainsi l‚Äô√©tat de l‚Äôart actuel, mais les performances pour une simulation en $K$ restent tr√®s faibles.

### Version avec d√©tection de cycle

(√Ä compl√©ter)

---

## Documentation

- [Vid√©o Science √âtonnante](https://www.youtube.com/watch?v=PlzV4aJ7iMI)  
- [Tutoriel Lenia initial](https://colab.research.google.com/github/OpenLenia/Lenia-Tutorial/blob/main/Tutorial_From_Conway_to_Lenia.ipynb#scrollTo=ycvjBlAOt6tK)  
- [Lenia and Expanded Universe (Article)](https://arxiv.org/pdf/2005.03742)  
- [Lenia ‚Äî Biology of Artificial Life (Article)](https://arxiv.org/pdf/1812.05433)
- [Generative Models for Periodicity Detection in Noisy Signals (Article)](https://arxiv.org/pdf/2201.07896)
- [FFT on GPU](https://www.kennethmoreland.com/fftgpu/fftgpu.pdf)